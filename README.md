# Emotion-Detection-System-from-Voice-Analysis

# Objective: 
The primary objectives of this project are:  
- To develop a machine learning model capable of classifying emotions from voice recordings.  
- To implement a real-time recording system for live emotion detection.  
- To create an interactive and visually appealing interface for users.  
- To ensure high accuracy in emotion prediction using feature extraction techniques.

# Tools
- Librosa – For audio feature extraction (MFCC, chroma, mel spectrogram)  
- Scikit-learn – For machine learning (SVM classifier, data preprocessing)  
- Matplotlib – For visualization of results  
- IPython & Google Colab – For interactive web-based execution  
- Pydub – For audio file handling  
- Joblib – For model serialization  

# Dataset
- RAVDESS (Ryerson Audio-Visual Database of Emotional Speech and Song)  
  - Contains 24 professional actors (12 male, 12 female)  
  - 8 emotional states: *neutral, calm, happy, sad, angry, fearful, disgust, surprised*  


